title: "01/MARZO/2018"
author: "EdgarGuevara"
date: "1 de marzo de 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
c.table<-array(data = c(251, 48, 34, 5), dim = c(2,2), dimnames =
list(Primero = c("éxito", "fracaso"),Segundo = c("éxito", "fracaso")))
list(Primero = c("éxito", "fracaso"), Segundo = c("éxito", "fracaso"))
c.table
pi.hat.table<-c.table/rowSums(c.table)
pi.hat.table
alpha <- 0.05
pi.hat1 <- pi.hat.table[1,1]
pi.hat2 <- pi.hat.table[2,1]
var.wald <- pi.hat1*(1-pi.hat1)/sum(c.table[1,]) + pi.hat2*(1-pi.hat2)/sum(c.table[2,])
#### Da los intervalos de lado izquierdo y lado derecho
(pi.hat1-pi.hat2) + qnorm(p=c(alpha/2,1-alpha/2)) * sqrt(var.wald)

```

#### Intervalo de Agresti y Caffo
## Revisar ??????
```{r}
pi.tilde1 <- (c.table[1,1]+1)/ sum(c.table[1,]+2)
pi.tilde2 <- (c.table[2,1]+1)/ sum(c.table[2,]+2)
var.AC <- pi.tilde1*(1-pi.tilde1)/sum(c.table[1,]+2)+pi.tilde2*(1-pi.tilde2)/ sum(c.table[2,]+2)
pi.tilde1 - pi.tilde2 + qnorm(p=c(alpha/2,1-alpha/2)) *sqrt(var.AC)

```

### 2 da Opcion de Calcular intervalos

```{r}
w1 <- 251
n1 <- 285
w2 <- 48
n2 <- 53

#### Intervalo de Wald
pi.hat1 <- w1/n1
pi.hat2 <- w2/n2
var.wald <- pi.hat1*(1-pi.hat1)/n1 + pi.hat2*(1-pi.hat2)/n2
(pi.hat1-pi.hat2) + qnorm(p=c(alpha/2,1-alpha/2)) * sqrt(var.wald)

#### Intervalo de Agresti Caffo
pi.tilde1 <- (w1+1)/(n1+2)
pi.tilde2 <- (w2+1)/(n2+2)
var.AC <- pi.tilde1*(1-pi.tilde1)/ (n1+2) + pi.tilde2*(1-pi.tilde2)/ (n2+2)
pi.tilde1 - pi.tilde2 + qnorm(p=c(alpha/2,1-alpha/2)) *sqrt(var.AC)
```

```{r}
alpha <- .05
pi1 <- 0.2
pi2 <- 0.4
n1 <- 10
n2 <- 10
#### expand.grid = se utiliza para encontrar todas las posibles combinaciones.
w.all <- expand.grid(w1=0:n1, w2 =0:n2)
#w.all
pi.hat1 <- (0:n1)/n1
pi.hat2 <- (0:n1)/n2
pi.hat.all <- expand.grid(pi.hat1=pi.hat1,pi.hat2=pi.hat2)
#pi.hat.all
#### Al estar con variables binarias para encontrar las probabilidades hay que usar una distribucion normal
prob.w1 <- dbinom(x = 0:n1, size = n1, prob=pi1)
prob.w2 <- dbinom(x = 0:n2, size = n2, prob=pi2)
prob.all <-  expand.grid(prob.w1 = prob.w1, prob.w2 = prob.w2)
# Probabilidad conjunta como son independientes se multiplican las marginales
# Funcion masa de probabilidad
pmf <- prob.all$prob.w1* prob.all$prob.w2
pmf
# Probabilidad P(W1 =w1, W2=w2)
## Ver las primeras 6 combinaciones
(head(data.frame(w.all, pmf = round(pmf,4) )))
## Para ver la ultimas 6 combinaciones
(tail(data.frame(w.all, pmf = round(pmf,4) )))
```

# Nivel de Confianza verdadero para el intervalo de Wald
```{r}
var.wald <- pi.hat.all[,1]*(1-pi.hat.all[,1])/n1 + pi.hat.all[,2]*(1-pi.hat.all[,2])/n2
lower <- pi.hat.all[,1]- pi.hat.all[,2] - qnorm(p= 1-alpha/2) *sqrt(var.wald)
upper <- pi.hat.all[,1]- pi.hat.all[,2] + qnorm(p= 1-alpha/2) *sqrt(var.wald)
# cON ESTO VERIFICAMOS QUE LUGARES CUMPLEN O BINE ESTAN DENTRO DEL INTERVALO
save <- ifelse(test = pi1-pi2 > lower, yes = ifelse( test = pi1-pi2 < upper, yes = 1, no =0), no =0)
### Con esto obtenemos el veradero nivel de confianza
sum(save*pmf)

```

# Nivel de Confianza Verdadero para el intervalo de Agresti y Caffo
```{r}
pi1tilde <- (0:n1+1) / (n1+2)
pi2tilde <- (0:n2+1) / (n2+2)

pi.all.tilde <- expand.grid( pi1tilde=pi1tilde , pi2tilde=pi2tilde )
var.ac <- pi.all.tilde[,1]*(1-pi.all.tilde[,1])/ (n1+2) + 
          pi.all.tilde[,2]*(1-pi.all.tilde[,2])/ (n2+2)
lower.ac <- pi.all.tilde[,1]- pi.all.tilde[,2] - qnorm(p= 1-alpha/2) *sqrt(var.ac)
upper.ac <- pi.all.tilde[,1]- pi.all.tilde[,2] + qnorm(p= 1-alpha/2) *sqrt(var.ac)
save.ac <- ifelse(test = pi1-pi2 > lower.ac, yes = ifelse( test = pi1-pi2 < upper.ac, yes = 1, no =0), no =0)
sum(save.ac*pmf)
# Anterior (wald)
sum(save*pmf)

### LRT = Prubea de razon de verosimilitud
```
### PRUEBAS DE HIPÓTESIS

```{r}
prop.test(x= c.table, conf.level = .95, correct = FALSE)
pi.bar <- colSums(c.table)[1]/ sum(c.table)
log.Lambda <- c.table[1,1]*log(pi.bar/pi.hat.table[1,1]) + c.table[1,2]*log((1-pi.bar)/(1-pi.hat.table[1,1])) + c.table[2,1]*log(pi.bar/pi.hat.table[2,1]) + c.table[2,2]*log((1-pi.bar)/(1-pi.hat.table[2,1]))
test.stat <- -2*log.Lambda
crit.val <- qchisq(p=.95, df=1)
p.val <- 1- pchisq(q =test.stat, df =1)
round(data.frame(pi.bar, test.stat, crit.val, p.val, row.names = NULL), 4)
install.packages("vcd")
require(vcd)
assocstats(x =c.table)

```







